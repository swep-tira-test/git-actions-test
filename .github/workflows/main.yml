on: 
  workflow_dispatch:
    inputs:
      task-docker-image:
        description: 'Docker image, which will try to solve the challenge'     
        required: true
        default: 'ubuntu:latest'
      task-docker-command:
        description: 'Command, which will be executed in the docker container'     
        required: true
        default: ''
      task-challenge-input-directory:
        description: 'Directory in which the input data can be accessed from the container'     
        required: true
        default: '/inputDataset'
      task-challenge-output-directory:
        description: 'Directory in which the challenge output data should be stored'     
        required: true
        default: '/outputOfRun'
        
      eval-docker-image:
        description: 'Docker image, which will evaluate the prediction'     
        required: true
        default: 'ubuntu:latest'
      eval-docker-command:
        description: 'Command, which will be executed in the evaluation docker container'     
        required: true
        default: ''
      eval-ground-truth-directory:
        description: 'Directory in which the ground truth data can be accessed from the evaluation container'     
        required: true
        default: '/inputGroundTruth'
      eval-output-directory:
        description: 'Directory in which the evaluation result will be saved'     
        required: true
        default: '/outputEval'
      
      runs-on:
        description: 'Whether the job should run on a self-hosted runner or on a runner hosted by Github (default)'     
        required: false
        default: 'ubuntu-latest'
        
      tira-preparation-container-image:
        description: 'Container Image, which will take care of the preparation and persist steps'     
        required: false
        default: 'webis/tira-git-pipelines:0.0.19'
        # possible values: 
        # for runners hosted by github: https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idruns-on
        # for self hosted runners:      https://docs.github.com/en/enterprise-server@3.4/actions/hosting-your-own-runners/using-self-hosted-runners-in-a-workflow#using-default-labels-to-route-jobs
      
      # currently not used and unable to use because there are max. 10 inputs are allowed
      # Error: "you may only define up to 10 `inputs` for a `workflow_dispatch` event"
      
      #cpu-cores:
      #  description: 'Number of CPU Cores for the runner'     
      #  required: false
      #  default: '2'
      #ram-gb:
      #  description: 'Amount of RAM in GB for the runner'     
      #  required: false
      #  default: '7'
        
jobs:
  evaluation:
    runs-on: ${{ inputs.runs-on }}
    name: run task container and evaluation container
    #outputs:
    #  output-from-docker: ${{ steps.docker.outputs.result }}
    steps:
  
      # get content of Repository into the current workingdirectory
      - name: Checkout Repo
        uses: actions/checkout@v3
        
      - name: create directories if not present
        run: |
          mkdir -p ${{ github.workspace }}/${{ inputs.task-challenge-input-directory }}
          mkdir -p ${{ github.workspace }}/${{ inputs.task-challenge-output-directory }}
          mkdir -p ${{ github.workspace }}/${{ inputs.eval-ground-truth-directory }}
          mkdir -p ${{ github.workspace }}/${{ inputs.eval-output-directory }}
          
      - id: prepare-tira-environment
        name: Provisioning 1 prepare environment
        uses: addnab/docker-run-action@v3
        with:
          #username: ${{ secrets.DOCKER_USERNAME }}
          #password: ${{ secrets.DOCKER_PASSWORD }}
          #registry: gcr.io
          image: ${{ inputs.tira-preparation-container-image}}
          options: | 
            -v ${{ github.workspace }}/${{ inputs.task-challenge-input-directory }}:/input
            -v ${{ github.workspace }}/${{ inputs.task-challenge-output-directory }}:/output
            -v ${{ github.workspace }}/:/prepare-tira/
          #shell: bash
          run: echo $PWD && python3 /prepare-tira/tira_ci_interface.py --step 1 > /task.env
        continue-on-error: false
        
      - id: run-user-software
        name: run user software
        uses: addnab/docker-run-action@v3
        with:
          #username: ${{ secrets.DOCKER_USERNAME }}
          #password: ${{ secrets.DOCKER_PASSWORD }}
          #registry: gcr.io
          image: ${{ inputs.task-docker-image }}
          options: | 
            -v ${{ github.workspace }}/${{ inputs.task-challenge-input-directory }}:/input
            -v ${{ github.workspace }}/${{ inputs.task-challenge-output-directory }}:/output
            --env-file ${{ github.workspace }}/task.env
            -e inputDataset=/input
            -e outputDir=/output
            --network none
          #shell: bash
          run: ${{ inputs.task-docker-command }}
        continue-on-error: true

      - name: debug print output dir
        run: ls -la ${{ github.workspace }}/${{ inputs.task-challenge-output-directory }}
                
      - id: persist-software-result
        name: Provisioning 2 Persist Software Result
        uses: addnab/docker-run-action@v3
        with:
          #username: ${{ secrets.DOCKER_USERNAME }}
          #password: ${{ secrets.DOCKER_PASSWORD }}
          #registry: gcr.io
          image: ${{ inputs.tira-preparation-container-image}}
          options: | 
            -v ${{ github.workspace }}/:/
            --env-file ${{ github.workspace }}/task.env
          #shell: bash
          run: ./tira_ci_interface.py --step 2
        continue-on-error: false
      
      - id: evaluate-software-result
        name: Evaluate Software Result
        uses: addnab/docker-run-action@v3
        with:
          #username: ${{ secrets.DOCKER_USERNAME }}
          #password: ${{ secrets.DOCKER_PASSWORD }}
          registry: ghcr.io
          image: ${{ inputs.eval-docker-image }}
          # input data (/inputRun) = output data of the to be evaluted container run
          options: | 
            -v ${{ github.workspace }}/${{ inputs.task-challenge-output-directory }}:/toBeEvaluated
            -v ${{ github.workspace }}/${{ inputs.eval-ground-truth-directory }}:/groundTruth
            -v ${{ github.workspace }}/${{ inputs.eval-output-directory }}:/outputEval
            --env-file ${{ github.workspace }}/task.env
            -e inputRun=/toBeEvaluated
            -e inputDataset=/groundTruth
            -e outputDir=/outputEval
            --network none
          #shell: bash
          run: ${{ inputs.eval-docker-command }}
        continue-on-error: true
        
      - id: persist-evaluation-result
        name: Provisioning 3 Persist Evaluation Result
        uses: addnab/docker-run-action@v3
        with:
          #username: ${{ secrets.DOCKER_USERNAME }}
          #password: ${{ secrets.DOCKER_PASSWORD }}
          #registry: gcr.io
          image: ${{ inputs.tira-preparation-container-image}}
          options: | 
            -v ${{ github.workspace }}/:/
            --env-file ${{ github.workspace }}/task.env
          #shell: bash
          run: ./tira_ci_interface.py --step 3
        continue-on-error: false
         
      - name: Upload Evaluation Result
        uses: actions/upload-artifact@v3
        with:
          name: evaluation-result
          path: ${{ github.workspace }}/${{ inputs.eval-output-directory }}
          retention-days: 3
