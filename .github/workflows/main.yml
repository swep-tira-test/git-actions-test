on: 
  push:
  workflow_dispatch:
    inputs:
      # now: env.TIRA_IMAGE_TO_EXECUTE
      task-docker-image:
        description: 'Docker image, which will try to solve the challenge'     
        required: true
        default: 'ubuntu:latest'
      # now: env.TIRA_COMMAND_TO_EXECUTE
      task-docker-command:
        description: 'Command, which will be executed in the docker container'     
        required: true
        default: ''
        
      # now: env.TIRA_DATASET_TASK_INPUT_PATH
      task-challenge-input-directory:
        description: 'Directory in which the input data can be accessed from the container'     
        required: true
        default: '/inputDataset'
        
      # now: env.TIRA_DATASET_TASK_OUTPUT_PATH
      # this is also the directory from where the evaluator will receive the to be evaluated input
      task-challenge-output-directory:
        description: 'Directory in which the challenge output data should be stored'     
        required: true
        default: '/outputOfRun'
      
      # now: env.TIRA_EVALUATION_IMAGE_TO_EXECUTE
      eval-docker-image:
        description: 'Docker image, which will evaluate the prediction'     
        required: true
        default: 'ubuntu:latest'
      # now: env.TIRA_EVALUATION_COMMAND_TO_EXECUTE
      eval-docker-command:
        description: 'Command, which will be executed in the evaluation docker container'     
        required: true
        default: ''
        
      # now: env.TIRA_DATASET_EVAL_GROUND_TRUTH_PATH
      eval-ground-truth-directory:
        description: 'Directory in which the ground truth data can be accessed from the evaluation container'     
        required: true
        default: '/inputGroundTruth'
      # now: env.TIRA_DATASET_EVAL_OUTPUT_PATH
      eval-output-directory:
        description: 'Directory in which the evaluation result will be saved'     
        required: true
        default: '/outputEval'
      
      runs-on:
        description: 'Whether the job should run on a self-hosted runner or on a runner hosted by Github (default)'     
        required: false
        default: 'ubuntu-latest'
        
        # possible values: 
        # for runners hosted by github: https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idruns-on
        # for self hosted runners:      https://docs.github.com/en/enterprise-server@3.4/actions/hosting-your-own-runners/using-self-hosted-runners-in-a-workflow#using-default-labels-to-route-jobs
      
      # currently not used and unable to use because there are max. 10 inputs are allowed
      # Error: "you may only define up to 10 `inputs` for a `workflow_dispatch` event"
      
      #cpu-cores:
      #  description: 'Number of CPU Cores for the runner'     
      #  required: false
      #  default: '2'
      #ram-gb:
      #  description: 'Amount of RAM in GB for the runner'     
      #  required: false
      #  default: '7'
        
jobs:
  evaluation:
    #runs-on: ${{ inputs.runs-on }}
    runs-on: ubuntu-latest
    name: run task container and evaluation container
    #outputs:
    #  output-from-docker: ${{ steps.docker.outputs.result }}
    steps:
  
      # get content of Repository into the current working directory
      - name: Checkout Repo
        uses: actions/checkout@v3
        
      - name: create directories if not present
        run: |
          mkdir -p ${{ github.workspace }}/${{ env.TIRA_DATASET_TASK_INPUT_PATH }}
          mkdir -p ${{ github.workspace }}/${{ env.TIRA_DATASET_TASK_OUTPUT_PATH }}
          mkdir -p ${{ github.workspace }}/${{ env.TIRA_DATASET_EVAL_GROUND_TRUTH_PATH }}
          mkdir -p ${{ github.workspace }}/${{ env.TIRA_DATASET_EVAL_OUTPUT_PATH }}
          
      - id: prepare-tira-environment
        name: Provisioning 1 prepare environment
        uses: addnab/docker-run-action@v3
        with:
          #username: ${{ secrets.DOCKER_USERNAME }}
          #password: ${{ secrets.DOCKER_PASSWORD }}
          #registry: gcr.io
          image: webis/tira-git-pipelines:0.0.19
          # TODO: "-v ${{ github.workspace }}/:/tira/application/src/" is only there to test the new tira_ci_interface.py (located at the root of the rep)
          options: | 
            -v ${{ github.workspace }}/${{ env.TIRA_DATASET_TASK_INPUT_PATH }}:/input
            -v ${{ github.workspace }}/${{ env.TIRA_DATASET_TASK_OUTPUT_PATH }}:/output
            -v ${{ github.workspace }}/:/tira/application/src/
            -e GITHUB_WORKSPACE=${{ env.GITHUB_WORKSPACE }}
            -e THIS_IS_EXECUTED_ON_GITHUB=true
          #shell: bash
          run: |
            python3 /tira/application/src/tira_ci_interface.py --step 1 > /tira/application/src/task.env
            cat task.env
        
      - id: source-env
        name: source/import env variables into the workflow runner environment
        run: |
          cat ${{ github.workspace }}/task.env >> $GITHUB_ENV
        
        
      - id: run-user-software
        name: run user software
        uses: addnab/docker-run-action@v3
        with:
          #username: ${{ secrets.DOCKER_USERNAME }}
          #password: ${{ secrets.DOCKER_PASSWORD }}
          #registry: gcr.io
          image: ${{ env.TIRA_IMAGE_TO_EXECUTE }}
          options: | 
            -v ${{ github.workspace }}/${{ env.TIRA_DATASET_TASK_INPUT_PATH }}:/input
            -v ${{ github.workspace }}/${{ env.TIRA_DATASET_TASK_OUTPUT_PATH }}:/output
            --env-file ./task.env
            -e inputDataset=/input
            -e outputDir=/output
            --network none
          #shell: bash
          run: |
            test -n "${TIRA_OUTPUT_DIR}" && mkdir -p ${TIRA_OUTPUT_DIR}
            echo "${TIRA_COMMAND_TO_EXECUTE}"
            eval "${TIRA_COMMAND_TO_EXECUTE}"
            echo "${TIRA_CLEAN_UP_COMMAND}"
            eval "${TIRA_CLEAN_UP_COMMAND}"
          #  env|grep 'TIRA' > task.env
        continue-on-error: true

      - name: debug print output dir
        run: |
          ls -la ${{ github.workspace }}/
          ls -la ${{ github.workspace }}/${{ env.TIRA_DATASET_TASK_OUTPUT_PATH }}
                
      - name: debug print task.env file
        run: |
          cat ${{ github.workspace }}/task.env 

      - name: debug print env
        run: |
          printenv 

      - id: persist-software-result
        name: Provisioning 2 Persist Software Result
        uses: addnab/docker-run-action@v3
        with:
          #username: ${{ secrets.DOCKER_USERNAME }}
          #password: ${{ secrets.DOCKER_PASSWORD }}
          #registry: gcr.io
          image: webis/tira-git-pipelines:0.0.19
          options: | 
            -v ${{ github.workspace }}/:/tira/application/src/
            --env-file ./task.env
            -e GITHUB_WORKSPACE=${{ env.GITHUB_WORKSPACE }}
            -e THIS_IS_EXECUTED_ON_GITHUB=true
          #shell: bash
          run: |
            python3 /tira/application/src/tira_ci_interface.py --step 2
      
      - id: evaluate-software-result
        name: Evaluate Software Result
        uses: addnab/docker-run-action@v3
        with:
          #username: ${{ secrets.DOCKER_USERNAME }}
          #password: ${{ secrets.DOCKER_PASSWORD }}
          registry: ghcr.io
          image: ${{ env.TIRA_EVALUATION_IMAGE_TO_EXECUTE }}
          # input data (/inputRun) = output data of the to be evaluted container run
          options: | 
            -v ${{ github.workspace }}/${{ env.TIRA_DATASET_TASK_OUTPUT_PATH }}:/toBeEvaluated
            -v ${{ github.workspace }}/${{ env.TIRA_DATASET_EVAL_GROUND_TRUTH_PATH }}:/groundTruth
            -v ${{ github.workspace }}/${{ env.TIRA_DATASET_EVAL_OUTPUT_PATH }}:/outputEval
            --env-file ./task.env
            -e inputRun=/toBeEvaluated
            -e inputDataset=/groundTruth
            -e outputDir=/outputEval
            --network none
          #shell: bash
          run: |
            echo "${TIRA_EVALUATION_COMMAND_TO_EXECUTE}"
            eval "${TIRA_EVALUATION_COMMAND_TO_EXECUTE}"
          # env|grep 'TIRA' > task.env
        continue-on-error: true
        
      - id: persist-evaluation-result
        name: Provisioning 3 Persist Evaluation Result
        uses: addnab/docker-run-action@v3
        with:
          #username: ${{ secrets.DOCKER_USERNAME }}
          #password: ${{ secrets.DOCKER_PASSWORD }}
          #registry: gcr.io
          image: webis/tira-git-pipelines:0.0.19
          options: | 
            -v ${{ github.workspace }}/:/tira/application/src/
            --env-file ./task.env
            -e GITHUB_WORKSPACE=${{ env.GITHUB_WORKSPACE }}
            -e THIS_IS_EXECUTED_ON_GITHUB=true
          #shell: bash
          run: |
            python3 /tira/application/src/tira_ci_interface.py --step 3
        continue-on-error: false
         
      - name: Upload Evaluation Result
        uses: actions/upload-artifact@v3
        with:
          name: evaluation-result
          path: ${{ github.workspace }}/${{ env.TIRA_DATASET_EVAL_OUTPUT_PATH }}
          retention-days: 3
